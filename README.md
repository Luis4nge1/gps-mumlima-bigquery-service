# GPS BigQuery Microservice

Microservicio escalable y modular para procesamiento automÃ¡tico de datos GPS con simulaciÃ³n de subida a BigQuery.

## ğŸš€ CaracterÃ­sticas

- **API REST v3**: API versionada con prefijo `/api/v3/` y compatibilidad legacy
- **Procesamiento AutomÃ¡tico**: Scheduler configurable para procesar datos GPS cada X minutos
- **Arquitectura Modular**: Estructura escalable con separaciÃ³n de responsabilidades
- **Sistema HÃ­brido**: MigraciÃ³n gradual entre flujos legacy y nuevos con rollback automÃ¡tico
- **ValidaciÃ³n Robusta**: ValidaciÃ³n completa de datos GPS con limpieza automÃ¡tica
- **Manejo de Errores**: Sistema robusto de manejo de errores con reintentos automÃ¡ticos
- **MÃ©tricas y Monitoreo**: RecolecciÃ³n de mÃ©tricas detalladas para monitoreo
- **ConfiguraciÃ³n Flexible**: ConfiguraciÃ³n completa via variables de entorno
- **Backup AutomÃ¡tico**: Sistema de backup opcional para datos procesados
- **Health Checks**: Endpoints de salud para monitoreo de servicios

## ğŸ“‹ Requisitos

- Node.js >= 18.0.0
- Redis Server
- Acceso de escritura al directorio `tmp/`

## ğŸ› ï¸ InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd gps-bigquery-microservice
```

2. **Instalar dependencias**
```bash
npm install
```

3. **Configurar variables de entorno**
```bash
cp .env.example .env
# Editar .env con tu configuraciÃ³n
```

4. **Crear directorios necesarios**
```bash
mkdir -p tmp/backup
```

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno Principales

```env
# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
GPS_LIST_KEY=gps:history:global

# Scheduler
SCHEDULER_INTERVAL_MINUTES=5
SCHEDULER_ENABLED=true

# Archivos de salida
GPS_OUTPUT_FILE=tmp/gps_data.txt
GPS_BACKUP_ENABLED=true
GPS_BACKUP_PATH=tmp/backup/

# Backup Local (Procesamiento AtÃ³mico)
BACKUP_MAX_RETRIES=3
BACKUP_RETENTION_HOURS=24
BACKUP_STORAGE_PATH=tmp/atomic-backups/
ATOMIC_PROCESSING_ENABLED=true
```

Ver `.env.example` para configuraciÃ³n completa.

### ConfiguraciÃ³n de Backup Local

El sistema incluye un mecanismo de backup local para garantizar que no se pierdan datos durante el procesamiento atÃ³mico:

```env
# NÃºmero mÃ¡ximo de reintentos para procesar un backup
BACKUP_MAX_RETRIES=3

# Tiempo en horas para mantener archivos de backup antes de eliminarlos
BACKUP_RETENTION_HOURS=24

# Directorio donde se almacenan los archivos de backup
BACKUP_STORAGE_PATH=tmp/atomic-backups/

# Intervalo en minutos para ejecutar limpieza automÃ¡tica de backups
BACKUP_CLEANUP_INTERVAL_MINUTES=60

# Habilitar/deshabilitar procesamiento atÃ³mico (feature flag)
ATOMIC_PROCESSING_ENABLED=true

# Timeout en milisegundos para operaciones de procesamiento atÃ³mico
ATOMIC_PROCESSING_TIMEOUT_MS=30000
```

**Comportamiento del Sistema de Backup:**
- Cuando falla la subida a GCS, los datos se guardan en backup local
- El sistema reintenta procesar backups antes de procesar nuevos datos
- Los backups se eliminan automÃ¡ticamente despuÃ©s del tiempo de retenciÃ³n
- Si un backup excede el mÃ¡ximo de reintentos, se preserva para revisiÃ³n manual

## ğŸš€ Uso

### Modo Continuo (con Scheduler)
```bash
npm start
```

### EjecuciÃ³n Ãšnica
```bash
npm run start:once
```

### Modo Desarrollo
```bash
npm run dev
```

### ProducciÃ³n
```bash
npm run start:production
```

## ğŸŒ API REST v3

El microservicio expone una API REST versionada con el prefijo `/api/v3/`.

### ConfiguraciÃ³n de API

```env
# ConfiguraciÃ³n de API
API_VERSION=v3
API_BASE_PATH=/api/v3
API_BASE_URL=http://localhost:3003
```

### Endpoints Principales

#### Health Checks
- `GET /api/v3/health` - Health check bÃ¡sico
- `GET /api/v3/health/detailed` - Health check detallado
- `GET /api/v3/health/gcs` - Health check de Google Cloud Storage
- `GET /api/v3/health/bigquery` - Health check de BigQuery

#### MÃ©tricas
- `GET /api/v3/metrics` - MÃ©tricas generales del sistema
- `GET /api/v3/metrics/gcs` - MÃ©tricas especÃ­ficas de GCS
- `GET /api/v3/metrics/bigquery` - MÃ©tricas especÃ­ficas de BigQuery
- `GET /api/v3/metrics/costs` - MÃ©tricas de costos GCP

#### Procesamiento
- `GET /api/v3/status` - Estado del procesador
- `POST /api/v3/process` - Ejecutar procesamiento manual
- `POST /api/v3/batch-process` - Ejecutar procesamiento batch

#### Sistema HÃ­brido/MigraciÃ³n
- `GET /api/v3/hybrid/status` - Estado del sistema hÃ­brido
- `GET /api/v3/hybrid/metrics` - MÃ©tricas de migraciÃ³n
- `GET /api/v3/migration/phase` - Fase actual de migraciÃ³n
- `POST /api/v3/migration/phase` - Cambiar fase de migraciÃ³n

### Compatibilidad Legacy

Las rutas legacy `/api/massive-data/` siguen funcionando y son automÃ¡ticamente redirigidas a `/api/v3/`.

### DocumentaciÃ³n Completa

Ver [API_DOCUMENTATION.md](./API_DOCUMENTATION.md) para documentaciÃ³n completa de la API.

## ğŸ“Š Comandos Ãštiles

### Verificar Salud del Sistema
```bash
npm run health
```

### Ver MÃ©tricas
```bash
npm run metrics
```

### Validar ConfiguraciÃ³n
```bash
npm run validate-config
```

### Validar ConfiguraciÃ³n de Backup
```bash
npm run validate-backup-config
```

### Testing en Staging
```bash
# Ejecutar suite completa de tests de staging
npm run test:staging

# El test verifica:
# - ConfiguraciÃ³n del sistema
# - Feature flags de procesamiento atÃ³mico
# - ExtracciÃ³n atÃ³mica de datos
# - Sistema de backup local
# - Recovery de backups
# - Limpieza automÃ¡tica
# - Monitoreo y mÃ©tricas
# - Manejo de carga
```

## ğŸ—ï¸ Arquitectura

```
src/
â”œâ”€â”€ config/           # Configuraciones
â”‚   â”œâ”€â”€ env.js       # Variables de entorno
â”‚   â””â”€â”€ redis.js     # ConfiguraciÃ³n Redis
â”œâ”€â”€ services/         # LÃ³gica de negocio
â”‚   â”œâ”€â”€ GPSProcessorService.js  # Procesamiento principal
â”‚   â””â”€â”€ SchedulerService.js     # ProgramaciÃ³n automÃ¡tica
â”œâ”€â”€ repositories/     # Acceso a datos
â”‚   â””â”€â”€ RedisRepository.js      # Operaciones Redis
â”œâ”€â”€ adapters/         # Integraciones externas
â”‚   â””â”€â”€ BigQueryAdapter.js      # SimulaciÃ³n BigQuery
â”œâ”€â”€ utils/           # Utilidades
â”‚   â”œâ”€â”€ logger.js    # Sistema de logging
â”‚   â”œâ”€â”€ FileUtils.js # Utilidades de archivos
â”‚   â””â”€â”€ MetricsCollector.js # RecolecciÃ³n de mÃ©tricas
â”œâ”€â”€ middleware/      # Middleware
â”‚   â””â”€â”€ ErrorHandler.js # Manejo de errores
â”œâ”€â”€ validators/      # Validaciones
â”‚   â””â”€â”€ GPSValidator.js # ValidaciÃ³n GPS
â””â”€â”€ types/           # Definiciones de tipos
    â””â”€â”€ GPSTypes.js  # Tipos y esquemas GPS
```

## ğŸ”„ Flujo de Procesamiento

### Flujo AtÃ³mico (Nuevo - Recomendado)

**Problema Resuelto:** El procesamiento atÃ³mico elimina la pÃ©rdida de datos que ocurrÃ­a cuando llegaban nuevos datos mientras se procesaban los existentes.

#### Flujo Normal con Procesamiento AtÃ³mico
1. **Scheduler** ejecuta cada X minutos (configurable)
2. **AtomicRedisProcessor** extrae TODOS los datos de Redis de una vez:
   - Obtiene todos los datos de `gps:history:global`
   - Obtiene todos los datos de `mobile:history:global`
   - **Limpia inmediatamente ambas keys de Redis**
   - Redis queda disponible para recibir nuevos datos
3. **GPSValidator** valida y limpia los datos extraÃ­dos
4. **GPSProcessorService** procesa los datos en lotes
5. **GCS Upload** sube archivos a Google Cloud Storage
6. **BigQuery** procesa archivos desde GCS
7. **MetricsCollector** registra estadÃ­sticas del procesamiento

#### Flujo con Backup Local (cuando falla GCS)
1. **AtomicRedisProcessor** extrae datos de Redis y limpia inmediatamente
2. **GCS Upload** falla â†’ **BackupManager** guarda datos en backup local
3. **Scheduler** en siguiente ejecuciÃ³n:
   - Procesa backups pendientes PRIMERO
   - **BackupManager** reintenta subir backup a GCS
   - Si Ã©xito â†’ elimina backup
   - Si falla â†’ incrementa contador de reintentos
   - ContinÃºa con procesamiento normal de nuevos datos

#### Ventajas del Procesamiento AtÃ³mico
- âœ… **Cero pÃ©rdida de datos**: Redis se limpia inmediatamente despuÃ©s de la extracciÃ³n
- âœ… **Disponibilidad continua**: Redis recibe nuevos datos mientras se procesan los anteriores
- âœ… **RecuperaciÃ³n automÃ¡tica**: Backups locales garantizan que los datos no se pierdan
- âœ… **Monitoreo completo**: MÃ©tricas detalladas de backups y reintentos

### Flujo Legacy (Deshabilitado por defecto)
El flujo anterior se mantiene disponible configurando `ATOMIC_PROCESSING_ENABLED=false`, pero **no se recomienda** debido al riesgo de pÃ©rdida de datos.

## ğŸ“ˆ MÃ©tricas Disponibles

- **Procesamiento**: Total de ejecuciones, Ã©xito/fallo, tiempo promedio
- **Redis**: Conexiones, errores, estadÃ­sticas de datos
- **BigQuery**: Subidas exitosas/fallidas, registros procesados
- **ValidaciÃ³n**: Tasa de validaciÃ³n, registros vÃ¡lidos/invÃ¡lidos
- **Sistema**: Tiempo de actividad, uso de memoria

## ğŸ›¡ï¸ Manejo de Errores

- **Reintentos AutomÃ¡ticos**: Para errores recuperables
- **Circuit Breaker**: Previene cascadas de fallos
- **ClasificaciÃ³n de Errores**: CategorizaciÃ³n automÃ¡tica de errores
- **Logging Detallado**: Logs estructurados para debugging

## ğŸ“ Formato de Datos GPS

### Entrada (Redis)
```json
{
  "latitude": -12.0464,
  "longitude": -77.0428,
  "timestamp": "2024-01-15T10:30:00Z",
  "speed": 45.5,
  "heading": 180,
  "altitude": 150,
  "accuracy": 5,
  "device_id": "device_001"
}
```

### Salida (BigQuery/Archivo)
```json
{
  "id": "gps_device_001_1705312200000",
  "latitude": -12.0464,
  "longitude": -77.0428,
  "timestamp": "2024-01-15T10:30:00Z",
  "speed": 45.5,
  "heading": 180,
  "altitude": 150,
  "accuracy": 5,
  "device_id": "device_001",
  "processed_at": "2024-01-15T10:30:05Z",
  "validated_at": "2024-01-15T10:30:05Z",
  "validation_version": "1.0"
}
```

## ğŸ”§ Desarrollo

### Estructura de Commits
- `feat:` Nueva funcionalidad
- `fix:` CorrecciÃ³n de bugs
- `docs:` DocumentaciÃ³n
- `refactor:` RefactorizaciÃ³n
- `test:` Pruebas

### Agregar Nueva Funcionalidad

1. **Servicios**: LÃ³gica de negocio en `src/services/`
2. **Repositorios**: Acceso a datos en `src/repositories/`
3. **Adaptadores**: Integraciones en `src/adapters/`
4. **Validadores**: Validaciones en `src/validators/`

## ğŸš¨ Troubleshooting

### Error de ConexiÃ³n Redis
```bash
# Verificar Redis
redis-cli ping

# Verificar configuraciÃ³n
npm run validate-config
```

### Sin Datos para Procesar
```bash
# Verificar datos en Redis
redis-cli llen gps:history:global
```

### Errores de Permisos
```bash
# Verificar permisos del directorio tmp
chmod 755 tmp/
```

### Problemas con Backup Local

#### Verificar Estado de Backups
```bash
# Validar configuraciÃ³n de backup
npm run validate-backup-config

# Verificar archivos de backup pendientes
ls -la tmp/atomic-backups/

# Ver detalles de un backup especÃ­fico
cat tmp/atomic-backups/backup_gps_20250125_164500_abc123.json | jq '.'

# Verificar mÃ©tricas de backup en el endpoint de salud
curl http://localhost:3000/health | jq '.backups'
```

#### Backup Files Pendientes
```bash
# Listar backups por tipo
ls -la tmp/atomic-backups/backup_gps_* | wc -l    # Backups GPS
ls -la tmp/atomic-backups/backup_mobile_* | wc -l # Backups Mobile

# Verificar backups con muchos reintentos
find tmp/atomic-backups/ -name "*.json" -exec grep -l '"retryCount":[2-9]' {} \;

# Ver backups que exceden el mÃ¡ximo de reintentos
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'echo "=== $1 ==="; cat "$1" | jq ".metadata | select(.retryCount >= .maxRetries)"' _ {} \;
```

#### ResoluciÃ³n de Problemas Comunes

**1. Backups AcumulÃ¡ndose (no se procesan)**
```bash
# Verificar que el scheduler estÃ© habilitado
grep SCHEDULER_ENABLED .env

# Verificar logs del scheduler
tail -f logs/app.log | grep -i "backup\|scheduler"

# Forzar procesamiento manual de backups (si existe el comando)
npm run process-backups
```

**2. Backups Fallando Repetidamente**
```bash
# Verificar conectividad a GCS
npm run validate-gcp-setup

# Verificar permisos del bucket
gsutil ls -L gs://your-bucket-name/

# Ver errores especÃ­ficos en los backups
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'echo "=== $1 ==="; cat "$1" | jq ".metadata.errors"' _ {} \;
```

**3. Espacio en Disco por Backups**
```bash
# Ver tamaÃ±o total de backups
du -sh tmp/atomic-backups/

# Limpiar backups antiguos manualmente (mÃ¡s de 24 horas)
find tmp/atomic-backups/ -name "*.json" -mtime +1 -delete

# Limpiar backups que exceden mÃ¡ximo de reintentos (revisar primero)
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'cat "$1" | jq -e ".metadata.retryCount >= .metadata.maxRetries" > /dev/null && echo "$1"' _ {} \;
```

**4. Backup Corrupto o InvÃ¡lido**
```bash
# Validar formato JSON de backups
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'echo "Validating $1"; cat "$1" | jq . > /dev/null || echo "INVALID: $1"' _ {} \;

# Mover backups corruptos a directorio de revisiÃ³n
mkdir -p tmp/corrupted-backups/
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'cat "$1" | jq . > /dev/null || mv "$1" tmp/corrupted-backups/' _ {} \;
```

#### Comandos de Mantenimiento
```bash
# EstadÃ­sticas de backups
echo "Total backups: $(ls tmp/atomic-backups/*.json 2>/dev/null | wc -l)"
echo "GPS backups: $(ls tmp/atomic-backups/backup_gps_*.json 2>/dev/null | wc -l)"
echo "Mobile backups: $(ls tmp/atomic-backups/backup_mobile_*.json 2>/dev/null | wc -l)"

# Backup mÃ¡s antiguo
ls -lt tmp/atomic-backups/*.json 2>/dev/null | tail -1

# Backup mÃ¡s reciente
ls -lt tmp/atomic-backups/*.json 2>/dev/null | head -1

# Limpiar todos los backups (Â¡CUIDADO!)
# rm -f tmp/atomic-backups/*.json
```

## ğŸ“Š Monitoreo en ProducciÃ³n

### Health Check
```bash
curl http://localhost:3000/health
```

### MÃ©tricas (si estÃ¡ habilitado)
```bash
curl http://localhost:9090/metrics
```

### Logs
```bash
tail -f logs/app.log
```

## ğŸš€ Checklist de Despliegue a ProducciÃ³n

### Pre-Despliegue
- [ ] **ConfiguraciÃ³n validada**: `npm run validate-config`
- [ ] **Tests de staging pasados**: `npm run test:staging`
- [ ] **Feature flags configurados**: `ATOMIC_PROCESSING_ENABLED=true`
- [ ] **Backup configurado**: Verificar `BACKUP_MAX_RETRIES`, `BACKUP_RETENTION_HOURS`
- [ ] **Conectividad GCS**: `npm run validate-gcp`
- [ ] **Monitoreo configurado**: Endpoints `/health` funcionando

### Durante el Despliegue
- [ ] **Backup de configuraciÃ³n actual**
- [ ] **Despliegue gradual**: Comenzar con un servidor
- [ ] **Monitoreo activo**: Verificar logs y mÃ©tricas
- [ ] **Verificar procesamiento atÃ³mico**: Logs deben mostrar "extracciÃ³n atÃ³mica"
- [ ] **Verificar backups**: No deben acumularse backups pendientes

### Post-Despliegue
- [ ] **Health check**: `curl http://servidor:3000/health/detailed`
- [ ] **Verificar mÃ©tricas**: Confirmar `atomicProcessingEnabled: true`
- [ ] **Monitorear por 24h**: Verificar que no hay pÃ©rdida de datos
- [ ] **Verificar limpieza**: Backups antiguos se eliminan automÃ¡ticamente
- [ ] **Alertas configuradas**: Para backups que exceden reintentos

### Rollback (si es necesario)
- [ ] **Deshabilitar procesamiento atÃ³mico**: `ATOMIC_PROCESSING_ENABLED=false`
- [ ] **Procesar backups pendientes**: `npm run recovery`
- [ ] **Verificar integridad de datos**
- [ ] **Restaurar configuraciÃ³n anterior**

## ğŸ”® Roadmap

- [x] âœ… Procesamiento atÃ³mico de Redis
- [x] âœ… Sistema de backup local automÃ¡tico
- [x] âœ… Feature flags para control de funcionalidad
- [x] âœ… Monitoreo y mÃ©tricas detalladas
- [x] âœ… Tests de staging automatizados
- [ ] IntegraciÃ³n real con BigQuery API
- [ ] API REST para control manual
- [ ] Dashboard web de monitoreo
- [ ] Docker containerization
- [ ] Kubernetes deployment
- [ ] Alertas automÃ¡ticas avanzadas
- [ ] CompresiÃ³n de datos

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear rama feature (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ‘¥ Equipo

- **GPS Processing Team** - Desarrollo inicial

## ğŸ“ Soporte

Para soporte tÃ©cnico, crear un issue en el repositorio o contactar al equipo de desarrollo.