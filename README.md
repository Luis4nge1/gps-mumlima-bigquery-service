# GPS BigQuery Microservice

Microservicio escalable y modular para procesamiento autom√°tico de datos GPS con simulaci√≥n de subida a BigQuery.

## üöÄ Caracter√≠sticas

- **API REST v3**: API versionada con prefijo `/api/v3/` y compatibilidad legacy
- **Procesamiento Autom√°tico**: Scheduler configurable para procesar datos GPS cada X minutos
- **Arquitectura Modular**: Estructura escalable con separaci√≥n de responsabilidades
- **Sistema H√≠brido**: Migraci√≥n gradual entre flujos legacy y nuevos con rollback autom√°tico
- **Validaci√≥n Robusta**: Validaci√≥n completa de datos GPS con limpieza autom√°tica
- **Manejo de Errores**: Sistema robusto de manejo de errores con reintentos autom√°ticos
- **M√©tricas y Monitoreo**: Recolecci√≥n de m√©tricas detalladas para monitoreo
- **Configuraci√≥n Flexible**: Configuraci√≥n completa via variables de entorno
- **Backup Autom√°tico**: Sistema de backup opcional para datos procesados
- **Health Checks**: Endpoints de salud para monitoreo de servicios

## üìã Requisitos

- Node.js >= 18.0.0
- Redis Server
- Acceso de escritura al directorio `tmp/`

## üõ†Ô∏è Instalaci√≥n

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd gps-bigquery-microservice
```

2. **Instalar dependencias**
```bash
npm install
```

3. **Configurar variables de entorno**
```bash
cp .env.example .env
# Editar .env con tu configuraci√≥n
```

4. **Crear directorios necesarios**
```bash
mkdir -p tmp/backup
```

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno Principales

```env
# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
GPS_LIST_KEY=gps:history:global

# Scheduler
SCHEDULER_INTERVAL_MINUTES=5
SCHEDULER_ENABLED=true

# Archivos de salida
GPS_OUTPUT_FILE=tmp/gps_data.txt
GPS_BACKUP_ENABLED=true
GPS_BACKUP_PATH=tmp/backup/

# Backup Local (Procesamiento At√≥mico)
BACKUP_MAX_RETRIES=3
BACKUP_RETENTION_HOURS=24
BACKUP_STORAGE_PATH=tmp/atomic-backups/
ATOMIC_PROCESSING_ENABLED=true
```

Ver `.env.example` para configuraci√≥n completa.

### Configuraci√≥n de Backup Local

El sistema incluye un mecanismo de backup local para garantizar que no se pierdan datos durante el procesamiento at√≥mico:

```env
# N√∫mero m√°ximo de reintentos para procesar un backup
BACKUP_MAX_RETRIES=3

# Tiempo en horas para mantener archivos de backup antes de eliminarlos
BACKUP_RETENTION_HOURS=24

# Directorio donde se almacenan los archivos de backup
BACKUP_STORAGE_PATH=tmp/atomic-backups/

# Intervalo en minutos para ejecutar limpieza autom√°tica de backups
BACKUP_CLEANUP_INTERVAL_MINUTES=60

# Habilitar/deshabilitar procesamiento at√≥mico (feature flag)
ATOMIC_PROCESSING_ENABLED=true

# Timeout en milisegundos para operaciones de procesamiento at√≥mico
ATOMIC_PROCESSING_TIMEOUT_MS=30000
```

**Comportamiento del Sistema de Backup:**
- Cuando falla la subida a GCS, los datos se guardan en backup local
- El sistema reintenta procesar backups antes de procesar nuevos datos
- Los backups se eliminan autom√°ticamente despu√©s del tiempo de retenci√≥n
- Si un backup excede el m√°ximo de reintentos, se preserva para revisi√≥n manual

## üöÄ Uso

### Modo Continuo (con Scheduler)
```bash
npm start
```

### Ejecuci√≥n √önica
```bash
npm run start:once
```

### Modo Desarrollo
```bash
npm run dev
```

### Producci√≥n
```bash
npm run start:production
```

## üåê API REST v3

El microservicio expone una API REST versionada con el prefijo `/api/v3/`.

### Configuraci√≥n de API

```env
# Configuraci√≥n de API
API_VERSION=v3
API_BASE_PATH=/api/v3
API_BASE_URL=http://localhost:3003
```

### Endpoints Principales

#### Health Checks
- `GET /api/v3/health` - Health check b√°sico
- `GET /api/v3/health/detailed` - Health check detallado
- `GET /api/v3/health/gcs` - Health check de Google Cloud Storage
- `GET /api/v3/health/bigquery` - Health check de BigQuery

#### M√©tricas
- `GET /api/v3/metrics` - M√©tricas generales del sistema
- `GET /api/v3/metrics/gcs` - M√©tricas espec√≠ficas de GCS
- `GET /api/v3/metrics/bigquery` - M√©tricas espec√≠ficas de BigQuery
- `GET /api/v3/metrics/costs` - M√©tricas de costos GCP

#### Procesamiento
- `GET /api/v3/status` - Estado del procesador
- `POST /api/v3/process` - Ejecutar procesamiento manual
- `POST /api/v3/batch-process` - Ejecutar procesamiento batch

#### Sistema H√≠brido/Migraci√≥n
- `GET /api/v3/hybrid/status` - Estado del sistema h√≠brido
- `GET /api/v3/hybrid/metrics` - M√©tricas de migraci√≥n
- `GET /api/v3/migration/phase` - Fase actual de migraci√≥n
- `POST /api/v3/migration/phase` - Cambiar fase de migraci√≥n

### Compatibilidad Legacy

Las rutas legacy `/api/massive-data/` siguen funcionando y son autom√°ticamente redirigidas a `/api/v3/`.

### Documentaci√≥n Completa

Ver [API_DOCUMENTATION.md](./API_DOCUMENTATION.md) para documentaci√≥n completa de la API.

## üìä Comandos √ötiles

### Verificar Salud del Sistema
```bash
npm run health
```

### Ver M√©tricas
```bash
npm run metrics
```

### Validar Configuraci√≥n
```bash
npm run validate-config
```

### Validar Configuraci√≥n de Backup
```bash
npm run validate-backup-config
```

### Testing en Staging
```bash
# Ejecutar suite completa de tests de staging
npm run test:staging

# El test verifica:
# - Configuraci√≥n del sistema
# - Feature flags de procesamiento at√≥mico
# - Extracci√≥n at√≥mica de datos
# - Sistema de backup local
# - Recovery de backups
# - Limpieza autom√°tica
# - Monitoreo y m√©tricas
# - Manejo de carga
```

## üèóÔ∏è Arquitectura

```
src/
‚îú‚îÄ‚îÄ config/           # Configuraciones
‚îÇ   ‚îú‚îÄ‚îÄ env.js       # Variables de entorno
‚îÇ   ‚îî‚îÄ‚îÄ redis.js     # Configuraci√≥n Redis
‚îú‚îÄ‚îÄ services/         # L√≥gica de negocio
‚îÇ   ‚îú‚îÄ‚îÄ GPSProcessorService.js  # Procesamiento principal
‚îÇ   ‚îî‚îÄ‚îÄ SchedulerService.js     # Programaci√≥n autom√°tica
‚îú‚îÄ‚îÄ repositories/     # Acceso a datos
‚îÇ   ‚îî‚îÄ‚îÄ RedisRepository.js      # Operaciones Redis
‚îú‚îÄ‚îÄ adapters/         # Integraciones externas
‚îÇ   ‚îî‚îÄ‚îÄ BigQueryAdapter.js      # Simulaci√≥n BigQuery
‚îú‚îÄ‚îÄ utils/           # Utilidades
‚îÇ   ‚îú‚îÄ‚îÄ logger.js    # Sistema de logging
‚îÇ   ‚îú‚îÄ‚îÄ FileUtils.js # Utilidades de archivos
‚îÇ   ‚îî‚îÄ‚îÄ MetricsCollector.js # Recolecci√≥n de m√©tricas
‚îú‚îÄ‚îÄ middleware/      # Middleware
‚îÇ   ‚îî‚îÄ‚îÄ ErrorHandler.js # Manejo de errores
‚îú‚îÄ‚îÄ validators/      # Validaciones
‚îÇ   ‚îî‚îÄ‚îÄ GPSValidator.js # Validaci√≥n GPS
‚îî‚îÄ‚îÄ types/           # Definiciones de tipos
    ‚îî‚îÄ‚îÄ GPSTypes.js  # Tipos y esquemas GPS
```

## üîÑ Flujo de Procesamiento

### Flujo At√≥mico (Nuevo - Recomendado)

**Problema Resuelto:** El procesamiento at√≥mico elimina la p√©rdida de datos que ocurr√≠a cuando llegaban nuevos datos mientras se procesaban los existentes.

#### Flujo Normal con Procesamiento At√≥mico
1. **Scheduler** ejecuta cada X minutos (configurable)
2. **AtomicRedisProcessor** extrae TODOS los datos de Redis de una vez:
   - Obtiene todos los datos de `gps:history:global`
   - Obtiene todos los datos de `mobile:history:global`
   - **Limpia inmediatamente ambas keys de Redis**
   - Redis queda disponible para recibir nuevos datos
3. **GPSValidator** valida y limpia los datos extra√≠dos
4. **GPSProcessorService** procesa los datos en lotes
5. **GCS Upload** sube archivos a Google Cloud Storage
6. **BigQuery** procesa archivos desde GCS
7. **MetricsCollector** registra estad√≠sticas del procesamiento

#### Flujo con Backup Local (cuando falla GCS)
1. **AtomicRedisProcessor** extrae datos de Redis y limpia inmediatamente
2. **GCS Upload** falla ‚Üí **BackupManager** guarda datos en backup local
3. **Scheduler** en siguiente ejecuci√≥n:
   - Procesa backups pendientes PRIMERO
   - **BackupManager** reintenta subir backup a GCS
   - Si √©xito ‚Üí elimina backup
   - Si falla ‚Üí incrementa contador de reintentos
   - Contin√∫a con procesamiento normal de nuevos datos

#### Ventajas del Procesamiento At√≥mico
- ‚úÖ **Cero p√©rdida de datos**: Redis se limpia inmediatamente despu√©s de la extracci√≥n
- ‚úÖ **Disponibilidad continua**: Redis recibe nuevos datos mientras se procesan los anteriores
- ‚úÖ **Recuperaci√≥n autom√°tica**: Backups locales garantizan que los datos no se pierdan
- ‚úÖ **Monitoreo completo**: M√©tricas detalladas de backups y reintentos

### Flujo Legacy (Deshabilitado por defecto)
El flujo anterior se mantiene disponible configurando `ATOMIC_PROCESSING_ENABLED=false`, pero **no se recomienda** debido al riesgo de p√©rdida de datos.

## üìà M√©tricas Disponibles

- **Procesamiento**: Total de ejecuciones, √©xito/fallo, tiempo promedio
- **Redis**: Conexiones, errores, estad√≠sticas de datos
- **BigQuery**: Subidas exitosas/fallidas, registros procesados
- **Validaci√≥n**: Tasa de validaci√≥n, registros v√°lidos/inv√°lidos
- **Sistema**: Tiempo de actividad, uso de memoria

## üõ°Ô∏è Manejo de Errores

- **Reintentos Autom√°ticos**: Para errores recuperables
- **Circuit Breaker**: Previene cascadas de fallos
- **Clasificaci√≥n de Errores**: Categorizaci√≥n autom√°tica de errores
- **Logging Detallado**: Logs estructurados para debugging

## üìù Formato de Datos GPS

### Entrada (Redis)
```json
{
  "latitude": -12.0464,
  "longitude": -77.0428,
  "timestamp": "2024-01-15T10:30:00Z",
  "speed": 45.5,
  "heading": 180,
  "altitude": 150,
  "accuracy": 5,
  "device_id": "device_001"
}
```

### Salida (BigQuery/Archivo)
```json
{
  "id": "gps_device_001_1705312200000",
  "latitude": -12.0464,
  "longitude": -77.0428,
  "timestamp": "2024-01-15T10:30:00Z",
  "speed": 45.5,
  "heading": 180,
  "altitude": 150,
  "accuracy": 5,
  "device_id": "device_001",
  "processed_at": "2024-01-15T10:30:05Z",
  "validated_at": "2024-01-15T10:30:05Z",
  "validation_version": "1.0"
}
```

## üîß Desarrollo

### Estructura de Commits
- `feat:` Nueva funcionalidad
- `fix:` Correcci√≥n de bugs
- `docs:` Documentaci√≥n
- `refactor:` Refactorizaci√≥n
- `test:` Pruebas

### Agregar Nueva Funcionalidad

1. **Servicios**: L√≥gica de negocio en `src/services/`
2. **Repositorios**: Acceso a datos en `src/repositories/`
3. **Adaptadores**: Integraciones en `src/adapters/`
4. **Validadores**: Validaciones en `src/validators/`

## üö® Troubleshooting

### Error de Conexi√≥n Redis
```bash
# Verificar Redis
redis-cli ping

# Verificar configuraci√≥n
npm run validate-config
```

### Sin Datos para Procesar
```bash
# Verificar datos en Redis
redis-cli llen gps:history:global
```

### Errores de Permisos
```bash
# Verificar permisos del directorio tmp
chmod 755 tmp/
```

### Problemas con Backup Local

#### Verificar Estado de Backups
```bash
# Validar configuraci√≥n de backup
npm run validate-backup-config

# Verificar archivos de backup pendientes
ls -la tmp/atomic-backups/

# Ver detalles de un backup espec√≠fico
cat tmp/atomic-backups/backup_gps_20250125_164500_abc123.json | jq '.'

# Verificar m√©tricas de backup en el endpoint de salud
curl http://localhost:3000/health | jq '.backups'
```

#### Backup Files Pendientes
```bash
# Listar backups por tipo
ls -la tmp/atomic-backups/backup_gps_* | wc -l    # Backups GPS
ls -la tmp/atomic-backups/backup_mobile_* | wc -l # Backups Mobile

# Verificar backups con muchos reintentos
find tmp/atomic-backups/ -name "*.json" -exec grep -l '"retryCount":[2-9]' {} \;

# Ver backups que exceden el m√°ximo de reintentos
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'echo "=== $1 ==="; cat "$1" | jq ".metadata | select(.retryCount >= .maxRetries)"' _ {} \;
```

#### Resoluci√≥n de Problemas Comunes

**1. Backups Acumul√°ndose (no se procesan)**
```bash
# Verificar que el scheduler est√© habilitado
grep SCHEDULER_ENABLED .env

# Verificar logs del scheduler
tail -f logs/app.log | grep -i "backup\|scheduler"

# Forzar procesamiento manual de backups (si existe el comando)
npm run process-backups
```

**2. Backups Fallando Repetidamente**
```bash
# Verificar conectividad a GCS
npm run validate-gcp-setup

# Verificar permisos del bucket
gsutil ls -L gs://your-bucket-name/

# Ver errores espec√≠ficos en los backups
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'echo "=== $1 ==="; cat "$1" | jq ".metadata.errors"' _ {} \;
```

**3. Espacio en Disco por Backups**
```bash
# Ver tama√±o total de backups
du -sh tmp/atomic-backups/

# Limpiar backups antiguos manualmente (m√°s de 24 horas)
find tmp/atomic-backups/ -name "*.json" -mtime +1 -delete

# Limpiar backups que exceden m√°ximo de reintentos (revisar primero)
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'cat "$1" | jq -e ".metadata.retryCount >= .metadata.maxRetries" > /dev/null && echo "$1"' _ {} \;
```

**4. Backup Corrupto o Inv√°lido**
```bash
# Validar formato JSON de backups
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'echo "Validating $1"; cat "$1" | jq . > /dev/null || echo "INVALID: $1"' _ {} \;

# Mover backups corruptos a directorio de revisi√≥n
mkdir -p tmp/corrupted-backups/
find tmp/atomic-backups/ -name "*.json" -exec sh -c 'cat "$1" | jq . > /dev/null || mv "$1" tmp/corrupted-backups/' _ {} \;
```

#### Comandos de Mantenimiento
```bash
# Estad√≠sticas de backups
echo "Total backups: $(ls tmp/atomic-backups/*.json 2>/dev/null | wc -l)"
echo "GPS backups: $(ls tmp/atomic-backups/backup_gps_*.json 2>/dev/null | wc -l)"
echo "Mobile backups: $(ls tmp/atomic-backups/backup_mobile_*.json 2>/dev/null | wc -l)"

# Backup m√°s antiguo
ls -lt tmp/atomic-backups/*.json 2>/dev/null | tail -1

# Backup m√°s reciente
ls -lt tmp/atomic-backups/*.json 2>/dev/null | head -1

# Limpiar todos los backups (¬°CUIDADO!)
# rm -f tmp/atomic-backups/*.json
```

## üìä Monitoreo en Producci√≥n

### Health Check
```bash
curl http://localhost:3000/health
```

### M√©tricas (si est√° habilitado)
```bash
curl http://localhost:9090/metrics
```

### Logs
```bash
tail -f logs/app.log
```

## üöÄ Checklist de Despliegue a Producci√≥n

### Pre-Despliegue
- [ ] **Configuraci√≥n validada**: `npm run validate-config`
- [ ] **Tests de staging pasados**: `npm run test:staging`
- [ ] **Feature flags configurados**: `ATOMIC_PROCESSING_ENABLED=true`
- [ ] **Backup configurado**: Verificar `BACKUP_MAX_RETRIES`, `BACKUP_RETENTION_HOURS`
- [ ] **Conectividad GCS**: `npm run validate-gcp`
- [ ] **Monitoreo configurado**: Endpoints `/health` funcionando

### Durante el Despliegue
- [ ] **Backup de configuraci√≥n actual**
- [ ] **Despliegue gradual**: Comenzar con un servidor
- [ ] **Monitoreo activo**: Verificar logs y m√©tricas
- [ ] **Verificar procesamiento at√≥mico**: Logs deben mostrar "extracci√≥n at√≥mica"
- [ ] **Verificar backups**: No deben acumularse backups pendientes

### Post-Despliegue
- [ ] **Health check**: `curl http://servidor:3000/health/detailed`
- [ ] **Verificar m√©tricas**: Confirmar `atomicProcessingEnabled: true`
- [ ] **Monitorear por 24h**: Verificar que no hay p√©rdida de datos
- [ ] **Verificar limpieza**: Backups antiguos se eliminan autom√°ticamente
- [ ] **Alertas configuradas**: Para backups que exceden reintentos

### Rollback (si es necesario)
- [ ] **Deshabilitar procesamiento at√≥mico**: `ATOMIC_PROCESSING_ENABLED=false`
- [ ] **Procesar backups pendientes**: `npm run recovery`
- [ ] **Verificar integridad de datos**
- [ ] **Restaurar configuraci√≥n anterior**

## üîÆ Roadmap

- [x] ‚úÖ Procesamiento at√≥mico de Redis
- [x] ‚úÖ Sistema de backup local autom√°tico
- [x] ‚úÖ Feature flags para control de funcionalidad
- [x] ‚úÖ Monitoreo y m√©tricas detalladas
- [x] ‚úÖ Tests de staging automatizados
- [ ] Integraci√≥n real con BigQuery API
- [ ] API REST para control manual
- [ ] Dashboard web de monitoreo
- [ ] Docker containerization
- [ ] Kubernetes deployment
- [ ] Alertas autom√°ticas avanzadas
- [ ] Compresi√≥n de datos

## ü§ù Contribuci√≥n

1. Fork el proyecto
2. Crear rama feature (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## üë• Equipo

- **GPS Processing Team** - Desarrollo inicial

## üìû Soporte

Para soporte t√©cnico, crear un issue en el repositorio o contactar al equipo de desarrollo.